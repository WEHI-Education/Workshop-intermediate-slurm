<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Intermediate Slurm: Memory and GPU utilization</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"><link rel="manifest" href="site.webmanifest"><link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/03-moremonitoring.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Intermediate Slurm
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Intermediate Slurm
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled><input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset></form>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Intermediate Slurm
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 33%" class="percentage">
    33%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 33%" aria-valuenow="33" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/03-moremonitoring.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-cpumonitoring.html">2. Monitoring a Jobs performance</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        3. Memory and GPU utilization
        </span>
      </button>
    </div><!--/div.accordion-header-->
        
    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#investigating-other-implementations-of-the-pi-algorithm">Investigating other implementations of the <span class="math inline">\(\pi\)</span> algorithm</a></li>
<li><a href="#investigating-memory-usage-of-pi-cpu2">Investigating memory usage of <code>pi-cpu2</code></a></li>
<li><a href="#comparing-htop-and-seff-memory-values">Comparing <code>htop</code> and <code>seff</code> memory values</a></li>
<li><a href="#monitoring-gpu-activity">Monitoring GPU activity</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-jobarrays.html">4. Job Arrays</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-jobdependencies.html">5. Organising dependent Slurm jobs</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-rpython.html">6. R and Python Slurm scripts</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="02-cpumonitoring.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="04-jobarrays.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="02-cpumonitoring.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Monitoring a Jobs
        </a>
        <a class="chapter-link float-end" href="04-jobarrays.html" rel="next">
          Next: Job Arrays... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Memory and GPU utilization</h1>
        <p>Last updated on 2024-03-12 |
        
        <a href="https://github.com/WEHI-ResearchComputing/intermediate-slurm/edit/main/episodes/03-moremonitoring.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How do I track how much memory my jobs are using?</li>
<li>How do I select an appropriate memory value for my Slurm job?</li>
<li>How can I monitor performance of jobs that use GPUs?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Learn how to use <code>htop</code>, <code>seff</code>, and
<code>sacct</code> to view memory usage</li>
<li>Learn how to use <code>nvidia-smi</code>, <code>nvtop</code>, and
<code>dcgmstats</code> to query GPU activity</li>
</ul></div>
</div>
</div>
</div>
</div>
<section id="investigating-other-implementations-of-the-pi-algorithm"><h2 class="section-heading">Investigating other implementations of the <span class="math inline">\(\pi\)</span> algorithm<a class="anchor" aria-label="anchor" href="#investigating-other-implementations-of-the-pi-algorithm"></a>
</h2>
<hr class="half-width"><p>Some time after your initial investigation, your supervisor shares
that the authors of the previous <code>pi-cpu</code> program has now
released the <code>pi-cpu2</code> program, as well as the
<code>pi-gpu</code> program - both implementing the same algorithm for
calculating <span class="math inline">\(\pi\)</span>.
<code>pi-gpu</code> ports the <span class="math inline">\(\pi\)</span>
calculation algorithm to the GPU, and <code>pi-cpu2</code> changes the
algorithm to improve speed at the cost of memory usage.</p>
</section><section id="investigating-memory-usage-of-pi-cpu2"><h2 class="section-heading">Investigating memory usage of <code>pi-cpu2</code><a class="anchor" aria-label="anchor" href="#investigating-memory-usage-of-pi-cpu2"></a>
</h2>
<hr class="half-width"><p>In the example programs, there should be the <code>pi-cpu2</code>
executable. Lets verify the authors claims that it should be faster
using <code>srun</code>. Make sure to add the <code>--constraint</code>
option to ensure your times are consistent!</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--constraint</span><span class="op">=</span>Icelake pi-cpu2</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>srun: job 12064697 queued and waiting for resources
srun: job 12064697 has been allocated resources
slurmstepd: error: Detected 1 oom_kill event in StepId=12064697.0. Some of the step tasks have been OOM Killed.
srun: error: il-n01: task 0: Out Of Memory</code></pre>
</div>
<p>Ok, that wasn’t what we expected! The error message says that our job
was <code>OOM Killed</code> and that <code>task 0: Out Of Memory</code>.
Here, <code>OOM</code> is an abbreviation for Out Of Memory. The overall
error message is indicating that your job exceeded the memory allocation
of your job, which caused Slurm to cancel it. If we use
<code>seff</code> on that job:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">seff</span> 12064697</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Job ID: 12064697
Cluster: milton
User/Group: yang.e/allstaff
State: OUT_OF_MEMORY (exit code 0)
Nodes: 1
Cores per node: 2
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:00:00 core-walltime
Job Wall-clock time: 00:00:00
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 20.00 MB (10.00 MB/core)</code></pre>
</div>
<p>You will find that it produces only the requested resources and the
<code>OUT_OF_MEMORY</code> state and no utilization information is
found. Similarly, if we execute <code>sacct</code>, we should see
<code>OUT_OF_ME+</code> and <code>0:125</code> under the
<code>STATE</code> and <code>ExitCode</code> columns, respectively:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">sacct</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>JobID           JobName  Partition    Account  AllocCPUS      State ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- --------
... skipped output...
12064697        pi-cpu2    regular       wehi          2 OUT_OF_ME+    0:125 
12064697.ex+     extern                  wehi          2 OUT_OF_ME+    0:125 
12064697.0      pi-cpu2                  wehi          2 OUT_OF_ME+    0:125</code></pre>
</div>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>This job failed because it started and then ran out of memory almost
immediately. Some jobs may only request large amounts of memory after
the program has been running awhile. In those cases, <code>seff</code>
and <code>sacct</code> may still produce meaningful output.</p>
</div>
</div>
</div>
<p>Unfortunately, Slurm hasn’t given you a lot of information about how
much memory you <em>should</em> request. When you’re first testing out a
program, a good test is to run the program on your laptop or on the
login node (for a short amount of time) and monitor the process using
<code>htop</code>.</p>
<div id="revising-htop" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="revising-htop" class="callout-inner">
<h3 class="callout-title">Revising<code>htop</code><a class="anchor" aria-label="anchor" href="#revising-htop"></a>
</h3>
<div class="callout-content">
<p>You learnt how to use <code>htop</code> in the previous lesson, but
for when your job is running on a compute node. So you can find out how
much memory to request from Slurm, try run <code>pi-cpu2</code> on one
of the login nodes to see how much memory it needs. Remember: you’re
interested in the <code>RES</code> column!</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>On one of the login nodes, execute the <code>pi-cpu2</code> program.
You will want to ensure it runs indefinitely, so you have time to run
<code>htop</code>:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">./pi-cpu2</span> <span class="at">-r</span> <span class="at">-1</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Result: 3.1418780541911 Error:  0.0002853131785 Time: 6.2856s
Result: 3.1416545913891 Error:  0.0000618503765 Time: 4.6628s
Result: 3.1414653105873 Error: -0.0001274304252 Time: 4.1556s
... It will continue on...</code></pre>
</div>
<p>In another terminal, you can ssh to the same login node you ran
<code>pi-cpu2</code> on and then run <code>htop</code>:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">ssh</span> slurm-login01</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="ex">htop</span> <span class="at">-u</span> <span class="va">$USER</span></span></code></pre>
</div>
<figure><img src="fig/htop-screenshot-pi2.png" alt="htop screenshot with pi-cpu2 running" class="figure mx-auto d-block"><div class="figcaption">
<code>htop</code> screenshot with
<code>pi-cpu2</code> running</div>
</figure><p>The RES column should show a <em>peak</em> usage of roughly 1900MB,
but that number will fluctuate while the program runs.</p>
</div>
</div>
</div>
</div>
<p>You now know that requesting 2GB of memory from Slurm should be
sufficient. The default memory on Milton is 10MB per CPU, and that
definitely wouldn’t be enough! Try running <code>pi-cpu2</code> with the
appropriate amount of memory:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--mem</span><span class="op">=</span>2G <span class="at">--constraint</span><span class="op">=</span>Icelake pi-cpu2</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>srun: job 12066042 queued and waiting for resources
srun: job 12066042 has been allocated resources
Result: 3.1416610065891 Error:  0.0000682655765 Time: 2.9627s
Result: 3.1416797985893 Error:  0.0000870575767 Time: 2.9501s
Result: 3.1418230713906 Error:  0.0002303303780 Time: 2.9519s</code></pre>
</div>
<p>And it’s now running successfully! We can also see that the program
is indeed faster, as the old version took roughly 3.6s for each
calculation of <span class="math inline">\(\pi\)</span> on one core.</p>
<div id="discussion3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion3"></a>
</h3>
<div class="callout-content">
<p>Determining how much memory to request from Slurm is not
straightforward. Sometimes, the documentation may provide some
indication of how much resources the software will use. However if this
isn’t the case, testing the program on your laptop or the login node can
be used to give an indication.</p>
<p>If your program uses too much memory, see if you can find smaller
test cases, and study how the memory usage changes with the size or
types of these inputs. You can use this to infer how much memory your
program might use with your real inputs.</p>
<p>But if neither of those options are available, the easiest way to go
about it is to over-allocate and to use the tools discussed so far to
refine your future jobs’ resource request.</p>
</div>
</div>
</div>
</section><section id="comparing-htop-and-seff-memory-values"><h2 class="section-heading">Comparing <code>htop</code> and <code>seff</code> memory values<a class="anchor" aria-label="anchor" href="#comparing-htop-and-seff-memory-values"></a>
</h2>
<hr class="half-width"><p>You might be wondering how <code>htop</code> and <code>seff</code>
may be used differently, since they both provide information about your
job. Mainly, <code>htop</code> gives a more detailed view into your job,
whereas <code>seff</code> provides only a single summary stat.
Furthermore, <code>seff</code> results are only available at the end of
the job. Another important distinction between <code>htop</code> and
<code>seff</code>, is the accuracy of the statistics.</p>
<p>We now know that the maximum memory used by the <code>pi-cpu2</code>
program is approximately 1900MB. We can check this by trying to run the
program in Slurm, but requesting only 1800MB.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--mem</span><span class="op">=</span>1800M <span class="at">--constraint</span><span class="op">=</span>Icelake pi-cpu2</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>srun: job 12066092 queued and waiting for resources
srun: job 12066092 has been allocated resources
slurmstepd: error: Detected 1 oom_kill event in StepId=12066092.0. Some of the step tasks have been OOM Killed.
srun: error: il-n02: task 0: Out Of Memory</code></pre>
</div>
<p>This confirms our job’s maximum memory is somewhere between 1800MB
and 2GB (based on our runs so far). Now try running running
<code>pi-cpu2</code> on Slurm again with the right amount of memory.
Make the <code>pi-cpu2</code> program calculate <span class="math inline">\(\pi\)</span> 15 times with <code>-r 15</code>, so
it runs for long enough for memory usage stats to be collected by
Slurm.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--mem</span><span class="op">=</span>2G <span class="at">--constraint</span><span class="op">=</span>Icelake pi-cpu2 <span class="at">-r</span> 15</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>srun: job 12066094 queued and waiting for resources
srun: job 12066094 has been allocated resources
Result: 3.1415999649886 Error:  0.0000072239760 Time: 2.9642s
... skipped output...</code></pre>
</div>
<p>And now let’s execute <code>seff</code> on the job and look at the
<code>Memory Utilized</code> field:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="ex">seff</span> 12066094</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>... skipped output...
Memory Utilized: 377.43 MB
Memory Efficiency: 18.43% of 2.00 GB</code></pre>
</div>
<p>We know that <code>pi-cpu2</code> will need at least 1800MB of memory
to even calculate <span class="math inline">\(\pi\)</span> once, but the
value shown by <code>seff</code> will be <em>far lower</em> than
that!</p>
<div id="slurm-job-resource-utilization-accuracy" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="slurm-job-resource-utilization-accuracy" class="callout-inner">
<h3 class="callout-title">Slurm job resource utilization accuracy<a class="anchor" aria-label="anchor" href="#slurm-job-resource-utilization-accuracy"></a>
</h3>
<div class="callout-content">
<p>Slurm collects job information by occasionally asking the system how
much resources the job is using. This is not a problem for jobs whose
memory usage stays steady throughout the lifetime of the job. However,
this is insufficient for jobs whose memory usage changes suddenly or
frequently.</p>
</div>
</div>
</div>
</section><section id="monitoring-gpu-activity"><h2 class="section-heading">Monitoring GPU activity<a class="anchor" aria-label="anchor" href="#monitoring-gpu-activity"></a>
</h2>
<hr class="half-width"><p>You’re consumed by the need-for-speed, and you’re ready to try the
<code>pi-gpu</code> program published by the same authors! When running
the program, you will need:</p>
<ul><li>1GB memory</li>
<li>1 GPU (of any kind)</li>
<li>the <code>cuda/11.7.1</code> and <code>gcc/11.2.0</code> modules
loaded</li>
</ul><div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="ex">module</span> load cuda/11.7.1 gcc/11.2.0</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--gres</span><span class="op">=</span>gpu:1 <span class="at">--mem</span><span class="op">=</span>1G <span class="at">--partition</span><span class="op">=</span>gpuq pi-gpu</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>srun: job 12066158 queued and waiting for resources
srun: job 12066158 has been allocated resources
Result: 3.1415535681881 Error: -0.0000390854017 Time: 0.2894s
Result: 3.1416463617890 Error:  0.0000537081992 Time: 0.2065s
Result: 3.1415584281882 Error: -0.0000342254016 Time: 0.2060s
...</code></pre>
</div>
<p>The job ran on a P100 GPU and it it’s about <code>3.0/0.2 = 15</code>
times faster than <code>pi-cpu2</code>! You find out from the
<code>--help</code> option, that <code>pi-gpu</code> also has a
<code>-p</code> option which can help you with running the program on
more GPUs on the same node. Try it out with <code>-p 2</code> and see if
you get a 2x speedup.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="ex">srun</span> <span class="at">--gres</span><span class="op">=</span>gpu:2 <span class="at">--mem</span><span class="op">=</span>1G <span class="at">--partition</span><span class="op">=</span>gpuq pi-gpu <span class="at">-p</span> 2</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>srun: job 12066179 queued and waiting for resources
srun: job 12066179 has been allocated resources
Result: 3.1415107353877 Error: -0.0000819182020 Time: 0.4006s
Result: 3.1417724625901 Error:  0.0001798090003 Time: 0.1990s
Result: 3.1413390477862 Error: -0.0002536058036 Time: 0.1988s
...</code></pre>
</div>
<p>The speedup seems to be minimal!</p>
<div class="section level3">
<h3 id="introducing-nvtop">Introducing <code>nvtop</code>
<a class="anchor" aria-label="anchor" href="#introducing-nvtop"></a></h3>
<p>Let’s investigate the program’s behavior on the GPUs. We’ll do this
inside a <code>salloc</code> session instead of via <code>srun</code>
like we have so far:</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="ex">salloc</span> <span class="at">--partition</span><span class="op">=</span>gpuq <span class="at">--gres</span><span class="op">=</span>gpu:2 <span class="at">--mem</span><span class="op">=</span>1G</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>salloc: Pending job allocation 12066180
salloc: job 12066180 queued and waiting for resources
salloc: job 12066180 has been allocated resources
salloc: Granted job allocation 12066180
salloc: Waiting for resource configuration
salloc: Nodes gpu-p100-n02 are ready for job</code></pre>
</div>
<p>Now on a seperate terminal, ssh to the node you’ve been allocated and
execute the <code>nvtop</code> command:</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">ssh</span> gpu-p100-n02</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="ex">nvtop</span></span></code></pre>
</div>
<p>A terminal user interface should open that looks similar to:</p>
<p><img src="fig/nvtop-screenshot-empty.png" alt="screenshot of nvtop output" class="figure"> Your output may differ if other
people’s jobs are running on the same node. The interface will be
reminiscent of <code>htop</code> but with differences:</p>
<ul><li>The top section doesn’t show the CPU utilization bars. Instead, they
show information about the device (we won’t be covering this
section).</li>
<li>The middle section shows a time-series chart of each GPU’s compute
(cyan) and memory (olive) utilization percentage over time.</li>
<li>The bottom section shows process information in a format similar to
<code>htop</code>:
<ul><li>
<code>PID</code>: process ID, which will correspond to a process on
<code>htop</code>
</li>
<li>
<code>USER</code>: The user the process is owned by</li>
<li>
<code>DEV</code>: the GPU ID the process is running on</li>
<li>
<code>GPU</code>: the “compute” utilization of the GPU (in
percentage)</li>
<li>
<code>GPU MEM</code>: the memory utilization of the GPU (in MB)</li>
<li>
<code>CPU</code>: the CPU utilization of the process</li>
<li>
<code>HOST MEM</code>: the CPU memory utilization of the
process</li>
<li>
<code>Command</code>: the command that the GPU is running</li>
</ul></li>
</ul><p><code>nvtop</code> is a useful tool in evaluating utilization of the
GPU while your job is running. This tool can be used as a way to check
that</p>
<ol style="list-style-type: lower-alpha"><li>the GPUs you requested are actually being used, and</li>
<li>that they are being fully utilized</li>
</ol><p>Back in your <code>salloc</code> session, try running
<code>pi-gpu -p 2 -r -1</code> again. The <code>-r -1</code> option is
added to ensure it continues running. Once it’s running, return to your
<code>nvtop</code> window.</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> 2 <span class="at">-r</span> <span class="at">-1</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Result: 3.1415107353877 Error: -0.0000819182020 Time: 0.4045s
Result: 3.1417724625901 Error:  0.0001798090003 Time: 0.1996s
Result: 3.1413390477862 Error: -0.0002536058036 Time: 0.1987s
...</code></pre>
</div>
<figure><img src="fig/nvtop-screenshot-m1.png" alt="nvtop interface with pi-gpu -p 2 -r -1 running" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> interface with
<code>pi-gpu -p 2 -r -1</code> running</div>
</figure><p>Two new processes would’ve popped up in the process list with your
<code>pi-gpu</code> command. You will also see that utilization charts
will start to move.</p>
<p>In the process list, you will see two entries corresponding to the
two GPUs that <code>pi-gpu</code> is using. Under <code>DEV</code> you
will see the device IDs which <code>pi-gpu</code> is using. In the
example screenshot above, they are GPU 0 and GPU 1. But,
<code>nvtop</code> shows the information for all the GPUs on the node by
default. To see the GPUs assigned to <code>pi-gpu</code>, quit
<code>nvtop</code> by pressing <code>q</code> on your keyboard, and then
execute <code>nvtop</code> again, but with the
<code>--gpu-select &lt;GPUs&gt;</code> where <code>&lt;GPUs</code> is a
colon (<code>:</code>) seperated list of GPU IDs. As per the example
above, the command would be:</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="ex">nvtop</span> <span class="at">--gpu-select</span> 0:1</span></code></pre>
</div>
<p>Change the ID’s based on the GPUs you see <code>pi-gpu</code> running
on. You should now see information only for the GPUs you specified:</p>
<figure><img src="fig/nvtop-screenshot-myjob.png" alt="nvtop with only our job’s GPUs" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> with only our job’s
GPUs</div>
</figure></div>
<div class="section level3">
<h3 id="interpreting-nvtop-output">Interpreting <code>nvtop</code> output<a class="anchor" aria-label="anchor" href="#interpreting-nvtop-output"></a></h3>
<p>A good place to start when determining if your program is using the
GPU well is looking at the utilization. Many programs have parameters
which can affect this utilization - especially programs that process
data.</p>
<p>Many programs process data on the GPU in chunks as the GPU memory is
typically too small to handle the entire data set at once. These are
often controlled through chunk size or number of chunks parameters (you
might also see the word “block” being used instead). Typically, you want
to tune the parameters such that utilization is high.</p>
<p>In our case, the GPU utilization of each GPU that <code>pi-gpu</code>
is using, is approximately 78%. Which is not necessarily ideal.</p>
<div id="seeing-chunk-size-in-action" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="seeing-chunk-size-in-action" class="callout-inner">
<h3 class="callout-title">Seeing chunk-size in action!<a class="anchor" aria-label="anchor" href="#seeing-chunk-size-in-action"></a>
</h3>
<div class="callout-content">
<p><code>pi-gpu</code> doesn’t process data, but it does have a
parameter which is similar to a data set chunk: the number of trials
parameter! In your <code>salloc</code> session, try changing the number
of trials <code>pi-gpu</code> uses using the <code>-n</code> flag
e.g.</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> 2 <span class="at">-r</span> <span class="at">-1</span> <span class="at">-n</span> <span class="op">&lt;</span>numtrials<span class="op">&gt;</span></span></code></pre>
</div>
<p>Note that the default is 123,456,789</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>Trying 12,345,678 (about 10x fewer trials than default):</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> 2 <span class="at">-r</span> <span class="at">-1</span> <span class="at">-n</span> 12345678</span></code></pre>
</div>
<figure><img src="fig/nvtop-screenshot-1e7.png" alt="nvtop shows pi-gpu GPU utilization at around 57% when number of trials is 10x less than default" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> shows <code>pi-gpu</code> GPU
utilization at around 57% when number of trials is 10x less than
default</div>
</figure><p>Trying 1,234,567 (about 100x fewer trials than default):</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> 2 <span class="at">-r</span> <span class="at">-1</span> <span class="at">-n</span> 1234567</span></code></pre>
</div>
<figure><img src="fig/nvtop-screenshot-1e6.png" alt="nvtop shows pi-gpu GPU utilization at around 40% when number of trials is 100x less than default" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> shows <code>pi-gpu</code> GPU
utilization at around 40% when number of trials is 100x less than
default</div>
</figure><p>Trying 500,000,000 (about 4x as many trials than default):</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> 2 <span class="at">-r</span> <span class="at">-1</span> <span class="at">-n</span> 500000000</span></code></pre>
</div>
<figure><img src="fig/nvtop-screenshot-5e8.png" alt="nvtop shows pi-gpu “spiky” GPU utilization when number of trials is 4x more than default" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> shows <code>pi-gpu</code>
“spiky” GPU utilization when number of trials is 4x more than
default</div>
</figure><p>Importantly, you should’ve seen that the utilization of the GPU grows
as you increase the number of trials for <code>pi-gpu</code> to use to
estimate <span class="math inline">\(\pi\)</span>! And the opposite
should also be observed when you lower the number of trials.</p>
<p>In this case, increasing the number of trials can be roughly
interpreted as giving the GPUs enough work to keep them busy, whereas if
too few trials are being used, then there may not be enough work to keep
the GPU’s “compute units” busy.</p>
<p>When tuning your GPU programs, it’s important to keep the GPU
utilized. Note that if you are <em>writing</em> a program that uses the
GPU, utilization is not the only consideration!</p>
</div>
</div>
</div>
</div>

<p>So far, we’ve highlighted GPU utilization as a key indicator of
performance, but we can see that on two P100 GPUs, <code>pi-gpu</code>
the utilization of both GPUs is at about 78% - not quite fully
utilized.</p>
<p>If you look at the output of <code>pi-gpu --help</code>, you’ll see
that the “mode” flag is available, which can be used to enable an
experimental, higher-performance, algorithm. Trying that “experimental
mode” with the default number of trials:</p>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="ex">srun</span> pi-gpu <span class="at">-p</span> <span class="at">-2</span> <span class="at">-r</span> <span class="at">-1</span> <span class="at">-m</span> 2</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Result: 3.1416099117887 Error:  0.0000172581989 Time: 0.2929s
Result: 3.1415823393884 Error: -0.0000103142014 Time: 0.0546s
Result: 3.1418233305906 Error:  0.0002306770008 Time: 0.0567s
...</code></pre>
</div>
<p>You should be able to see that the time to calculate <span class="math inline">\(\pi\)</span> is almost 4 times faster than the
default algorithm. If you look at the output of <code>nvtop</code>, you
should be able to see the difference in utilization:</p>
<figure><img src="fig/nvtop-screenshot-m2.png" alt="nvtop with the experimental algorithm enabled showing higher utilization" class="figure mx-auto d-block"><div class="figcaption">
<code>nvtop</code> with the experimental
algorithm enabled showing higher utilization</div>
</figure><p>In this case, the utilization has shot up to about 98%! GPU memory
utilization has also increased, which is a reflection of the algorithm
used in this new mode.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>Choosing the right memory for you Slurm jobs takes a bit of trial
and error, but it helps to know a bit about how your program
behaves!</li>
<li>
<code>htop</code> should be used to observe memory usage when memory
usage varies frequently throughout the lifespan of the program.
<code>sacct</code> and <code>seff</code> are good for programs that
maintain steady memory usage.</li>
<li>
<code>nvtop</code> is a <code>htop</code>-like tool for monitoring
GPU activity</li>
<li>When optimizing GPU programs’ parameters, try to aim for full
utilization!</li>
</ul></div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="02-cpumonitoring.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="04-jobarrays.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="02-cpumonitoring.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Monitoring a Jobs
        </a>
        <a class="chapter-link float-end" href="04-jobarrays.html" rel="next">
          Next: Job Arrays... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/WEHI-ResearchComputing/intermediate-slurm/edit/main/episodes/03-moremonitoring.Rmd" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/WEHI-ResearchComputing/intermediate-slurm/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/WEHI-ResearchComputing/intermediate-slurm/" class="external-link">Source</a></p>
				<p><a href="https://github.com/WEHI-ResearchComputing/intermediate-slurm/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:research.computing@wehi.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.3" class="external-link">sandpaper (0.16.3)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.4" class="external-link">pegboard (0.7.4)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://WEHI-ResearchComputing.github.io/intermediate-slurm/03-moremonitoring.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "Slurm, HPC",
  "name": "Memory and GPU utilization",
  "creativeWorkStatus": "active",
  "url": "https://WEHI-ResearchComputing.github.io/intermediate-slurm/03-moremonitoring.html",
  "identifier": "https://WEHI-ResearchComputing.github.io/intermediate-slurm/03-moremonitoring.html",
  "dateCreated": "2023-04-13",
  "dateModified": "2024-03-12",
  "datePublished": "2024-04-02"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

